# üá∞üá≠ Khmer Text Style Transformer (khmer-tst)

<div align="center">

**Bridging the gap between Common Khmer and Royal Registers (Reacheasap)**

</div>



## üìñ Overview

The **Khmer Text Style Transformer** is an NLP project dedicated to the preservation and digital transformation of the Khmer language's unique sociolinguistic registers. Specifically, it focuses on **Reacheasap (·ûö·û∂·ûá·û∂·ûü·ûñ·üí·ûë)** ‚Äî the highly formalized royal register used when referring to or addressing the Monarchy, Clergy, and in classical literature.

### üéØ Project Objectives

The project automates the transition between everyday vernacular and the sophisticated, honorific-heavy structures of formal Khmer.

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 
    'primaryColor': '#f0f0f0', 
    'primaryBorderColor': '#000000', 
    'lineColor': '#1f77b4',   %% arrows in blue
    'textColor': '#000000',
    'edgeLabelBackground':'#f0f0f0'
}}}%%
graph LR
    A[Data Acquisition] --> B[Corpus Cleaning]
    B --> C[ML Pre-training]
    C --> D[Domain Fine-tuning]

```




---

## ‚ú® Key Features

* **Register Transformation:** Seamlessly convert text between **Common (·ûí·ûò·üí·ûò·ûè·û∂)** and **Royal (·ûö·û∂·ûá·û∂·ûü·ûñ·üí·ûë)** registers.
* **Curated Parallel Corpus:** A high-quality dataset of 690+ manually verified Khmer sentence pairs.
* **Automated Scrapers:** Custom scripts designed to harvest rich Khmer linguistic data from Wikipedia and traditional folklore sources.
* **End-to-End Pipeline:** Includes notebooks for everything from data scraping and Masked Language Modeling (MLM) to final fine-tuning.

---

## üìä Linguistic Dataset

The core of this project is a parallel corpus of **690+ verified pairs**, capturing the nuance of Khmer honorifics.

| Register   | Example Sentence                                    |
| ---------- | --------------------------------------------------- |
| **Common** | ·ûÇ·û∂·ûè·üã·ûÜ·üí·ûõ·ûÑ·ûÄ·û∂·ûè·üã·ûÜ·üí·ûì·üÅ·ûö·ûü·ûò·ûª·ûë·üí·ûö ·ûî·û∂·ûì·ûë·üÖ·ûä·ûõ·üã·ûÄ·üÑ·üá·ûò·ûΩ·ûô              |
| **Royal**  | ·ûñ·üí·ûö·üá·û¢·ûÑ·üí·ûÇ·ûì·û∑·ûò·ûì·üí·ûä·ûÄ·û∂·ûè·üã·ûè·û∂·ûò·ûÜ·üí·ûì·üÅ·ûö·ûò·û†·û∂·ûü·û∂·ûÇ·ûö ·ûî·û∂·ûì·ûô·û∂·ûÑ·ûë·üÖ·ûä·ûõ·üã·ûÄ·üÑ·üá·ûò·ûΩ·ûô |

### Transformation Logic Breakdown

| Word (Common)       | Word (Royal)     | English Equivalent    |
| ------------------- | ---------------- | --------------------- |
| ·ûÇ·û∂·ûè·üã (He/She)       | **·ûñ·üí·ûö·üá·û¢·ûÑ·üí·ûÇ**     | His/Her Majesty       |
| ·ûâ·üâ·û∂·üÜ (Eat)          | **·ûü·üÑ·ûô**          | To partake (Royal)    |
| ·ûò·ûÄ (Come)           | **·ûô·û∂·ûÑ·ûò·ûÄ**        | To proceed / arrive   |
| ·ûÜ·üí·ûì·üÅ·ûö·ûü·ûò·ûª·ûë·üí·ûö (Coast) | **·ûÜ·üí·ûì·üÅ·ûö·ûò·û†·û∂·ûü·û∂·ûÇ·ûö** | The Great Ocean Coast |

---

## üìÅ Project Structure

```bash
khmer-tst/
‚îú‚îÄ‚îÄ üìä data/
‚îÇ   ‚îú‚îÄ‚îÄ general-text.txt       # Unstructured Khmer corpus for pre-training
‚îÇ   ‚îî‚îÄ‚îÄ normal-royal.csv       # The parallel register dataset
‚îú‚îÄ‚îÄ ü§ñ models/                  # Saved weights and transformer checkpoints
‚îú‚îÄ‚îÄ üìì notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01-scraping.ipynb      # Wikipedia & Folklore data collection
‚îÇ   ‚îú‚îÄ‚îÄ 02-pre-training.ipynb  # MLM on general Khmer text
‚îÇ   ‚îî‚îÄ‚îÄ 03-fine-tuning.ipynb   # Sequence-to-sequence register training
‚îî‚îÄ‚îÄ README.md
```

---

## üß† Model Training Workflow

The project follows a **two-phase training strategy** to develop a robust Khmer Text Style Transformer. The architecture is based on an **LSTM encoder‚Äìdecoder framework**, trained progressively to first learn general language structure, then adapt to register-specific nuances.

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 
    'primaryColor': '#f0f0f0', 
    'primaryBorderColor': '#000000', 
    'lineColor': '#1f77b4',   %% arrows in blue
    'textColor': '#000000',
    'edgeLabelBackground':'#f0f0f0'
}}}%%
graph TD
    A[Unsupervised Pre-Training] --> B[Fine-Tuning on Parallel Corpus]
    B --> C[Inference & Style Transformation]
```


### **1. Pre-Training Phase**

During this stage, the model is exposed to a **large unpaired Khmer text corpus** to learn the foundational syntax, morphology, and semantics of the language.

**Objective:**
Train the LSTM to predict the next token in a sequence, allowing it to learn contextual representations of Khmer words.

**Setup:**

* **Dataset:** `general-text.txt` (unstructured Khmer corpus)
* **Task:** Next-word prediction (language modeling)
* **Loss Function:** Cross-Entropy Loss
* **Optimizer:** Adam
* **Learning Rate:** 0.001
* **Epochs:** 20‚Äì30 (with early stopping)

This phase enables the model to build **general language representations**, capturing grammar and sequential dependencies in Khmer text.

---

### **2. Fine-Tuning Phase**

After pre-training, the model is fine-tuned on a **parallel corpus of Common‚ÄìRoyal sentence pairs**. This teaches the model to transform sentences from the **Common register** to the **Royal register**, leveraging the linguistic foundation learned during pre-training.

**Objective:**
Adapt the pretrained LSTM for **sequence-to-sequence translation** between registers.

**Setup:**

* **Dataset:** `normal-royal.csv` (690+ aligned sentence pairs)
* **Task:** Text style transfer (Common ‚Üí Royal)
* **Loss Function:** Cross-Entropy Loss
* **Optimizer:** Adam (lower learning rate for stability)
* **Evaluation Metrics:** BLEU score, perplexity
* **Model Checkpointing:** Best model saved as `best_model.pt`

This phase refines the model to capture **register-specific lexical and stylistic transformations**, producing fluent and contextually accurate royal text.

---

## üõ†Ô∏è Tech Stack

* **Linguistic Processing:** Custom tokenization for Khmer script.
* **Web Tools:** `BeautifulSoup4`for scraping traditional literature.
* **AI/ML:** `Pandas`, `PyTorch`, and `NumPy` for data processing and LSTM implementation.

---



<div align="center">

**Preserving Khmer Heritage through Modern Technology**

If this project helps your research, please consider giving it a ‚≠ê!

</div>

---

