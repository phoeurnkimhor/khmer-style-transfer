{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14267558,"sourceType":"datasetVersion","datasetId":9104670},{"sourceId":14269204,"sourceType":"datasetVersion","datasetId":9105929},{"sourceId":697985,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":529434,"modelId":543435}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport string\n\ndata = []\nwith open(\"/kaggle/input/khmer-text/general-text.txt\") as f:\n    for i, line in enumerate(f, 1):\n        data.append({'text' : line.replace('\\n', '')})\n        \ndf = pd.DataFrame(data)\ndf.head()\nprint(df.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:40.292074Z","iopub.execute_input":"2025-12-25T05:03:40.292350Z","iopub.status.idle":"2025-12-25T05:03:43.827476Z","shell.execute_reply.started":"2025-12-25T05:03:40.292302Z","shell.execute_reply":"2025-12-25T05:03:43.826707Z"}},"outputs":[{"name":"stdout","text":"(582511, 1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\ndf['text'] = df['text'].replace('', np.nan)\ndf.dropna(inplace=True)\nprint(df.shape)\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:43.828993Z","iopub.execute_input":"2025-12-25T05:03:43.829387Z","iopub.status.idle":"2025-12-25T05:03:44.032550Z","shell.execute_reply.started":"2025-12-25T05:03:43.829360Z","shell.execute_reply":"2025-12-25T05:03:44.031760Z"}},"outputs":[{"name":"stdout","text":"(471632, 1)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...\n4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import re\n\ndf['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\npattern = r'[^\\u1780-\\u17FF\\u17E0-\\u17E9\\s។៕៚៙៛ៜ៖]+'\n# Apply regex to clean each row\ndf['text'] = df['text'].apply(lambda x: re.sub(pattern, '', x))\ndf['text'] = df['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:44.033521Z","iopub.execute_input":"2025-12-25T05:03:44.033800Z","iopub.status.idle":"2025-12-25T05:03:55.211940Z","shell.execute_reply.started":"2025-12-25T05:03:44.033771Z","shell.execute_reply":"2025-12-25T05:03:55.211315Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:55.212920Z","iopub.execute_input":"2025-12-25T05:03:55.213202Z","iopub.status.idle":"2025-12-25T05:03:55.220263Z","shell.execute_reply.started":"2025-12-25T05:03:55.213170Z","shell.execute_reply":"2025-12-25T05:03:55.219644Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...\n4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def split_sentences(text):\n    sentences = re.split(r'[។៕]', text)\n    return [s.strip() for s in sentences if s.strip()]\n\ndf['sentences'] = df['text'].apply(split_sentences)\n\ndef chunk_text(sentence, chunk_size=120):\n    return [sentence[i:i + chunk_size] for i in range(0, len(sentence), chunk_size)]\n\ndf['chunks'] = df['sentences'].apply(lambda sents: [chunk for sent in sents for chunk in chunk_text(sent)])\n\ndf_exploded = df.explode('chunks', ignore_index=True)\ndf_exploded = df_exploded[df_exploded['chunks'].notna() & (df_exploded['chunks'] != '')]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:55.221102Z","iopub.execute_input":"2025-12-25T05:03:55.221396Z","iopub.status.idle":"2025-12-25T05:03:57.870677Z","shell.execute_reply.started":"2025-12-25T05:03:55.221363Z","shell.execute_reply":"2025-12-25T05:03:57.869825Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_new = pd.DataFrame({\n    'sentence': df_exploded['chunks'],\n    'target': df_exploded['chunks']\n})\n\ndf_new = df_new.iloc[:50000, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:57.871584Z","iopub.execute_input":"2025-12-25T05:03:57.871814Z","iopub.status.idle":"2025-12-25T05:03:57.898964Z","shell.execute_reply.started":"2025-12-25T05:03:57.871793Z","shell.execute_reply":"2025-12-25T05:03:57.898394Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom collections import Counter\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:03:57.900887Z","iopub.execute_input":"2025-12-25T05:03:57.901304Z","iopub.status.idle":"2025-12-25T05:04:01.509687Z","shell.execute_reply.started":"2025-12-25T05:03:57.901283Z","shell.execute_reply":"2025-12-25T05:04:01.508788Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def tokenize(text):\n    return list(text)\n\nall_text = df_new['sentence'].tolist()\ntokens = [t for sentence in all_text for t in tokenize(sentence)]\nvocab = sorted(set(tokens))\nstoi = {ch: i for i, ch in enumerate(vocab)}\nitos = {i: ch for ch, i in stoi.items()}\n\nvocab_size = len(vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:04:01.510817Z","iopub.execute_input":"2025-12-25T05:04:01.511280Z","iopub.status.idle":"2025-12-25T05:04:02.017469Z","shell.execute_reply.started":"2025-12-25T05:04:01.511252Z","shell.execute_reply":"2025-12-25T05:04:02.016583Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class TSTDataset(Dataset):\n    def __init__(self, texts, seq_len=50):\n        self.seq_len = seq_len\n        self.data = []\n        for sentence in texts:\n            token_ids = [stoi[ch] for ch in tokenize(sentence) if ch in stoi]\n            for i in range(len(token_ids) - seq_len):\n                self.data.append((token_ids[i:i+seq_len], token_ids[i+1:i+seq_len+1]))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        x, y = self.data[idx]\n        return torch.tensor(x), torch.tensor(y)\n\nseq_len = 50\nbatch_size = 64\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1  # must sum to 1.0\n\nn_total = len(all_text)\ntrain_end = int(n_total * train_ratio)\nval_end = train_end + int(n_total * val_ratio)\n\ntrain_texts = all_text[:train_end]\nval_texts = all_text[train_end:val_end]\ntest_texts = all_text[val_end:]\n\n# Create datasets\ntrain_dataset = TSTDataset(train_texts, seq_len=seq_len)\nval_dataset = TSTDataset(val_texts, seq_len=seq_len)\ntest_dataset = TSTDataset(test_texts, seq_len=seq_len)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nprint(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Val samples: {len(val_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:04:02.018605Z","iopub.execute_input":"2025-12-25T05:04:02.018984Z","iopub.status.idle":"2025-12-25T05:04:14.462284Z","shell.execute_reply.started":"2025-12-25T05:04:02.018957Z","shell.execute_reply":"2025-12-25T05:04:14.461654Z"}},"outputs":[{"name":"stdout","text":"Train samples: 1821741\nVal samples: 239909\nTest samples: 245100\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import torch.nn as nn\n\nclass LSTMTST(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden=None):\n        emb = self.embedding(x)\n        out, hidden = self.lstm(emb, hidden)\n        logits = self.fc(out)\n        return logits, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:04:14.463221Z","iopub.execute_input":"2025-12-25T05:04:14.463536Z","iopub.status.idle":"2025-12-25T05:04:14.468626Z","shell.execute_reply.started":"2025-12-25T05:04:14.463514Z","shell.execute_reply":"2025-12-25T05:04:14.467849Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# import torch\n# import math\n\n# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# model = LSTMTST(vocab_size).to(device)\n# criterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# epochs = 20\n# patience = 3  # stop after 3 epochs with no improvement\n# best_val_loss = float('inf')\n# wait = 0  \n\n# for epoch in range(epochs):\n#     model.train()\n#     total_train_loss = 0\n\n#     for x_batch, y_batch in train_loader:\n#         x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n#         optimizer.zero_grad()\n#         logits, _ = model(x_batch)\n#         loss = criterion(logits.view(-1, vocab_size), y_batch.view(-1))\n#         loss.backward()\n#         optimizer.step()\n\n#         total_train_loss += loss.item()\n\n#     avg_train_loss = total_train_loss / len(train_loader)\n#     train_ppl = math.exp(avg_train_loss)\n\n#     model.eval()\n#     total_val_loss = 0\n#     with torch.no_grad():\n#         for x_batch, y_batch in val_loader:\n#             x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n#             logits, _ = model(x_batch)\n#             loss = criterion(logits.view(-1, vocab_size), y_batch.view(-1))\n#             total_val_loss += loss.item()\n\n#     avg_val_loss = total_val_loss / len(val_loader)\n#     val_ppl = math.exp(avg_val_loss)\n\n#     print(\n#         f\"Epoch {epoch+1}/{epochs} | \"\n#         f\"Train Loss: {avg_train_loss:.4f} (PPL {train_ppl:.2f}) | \"\n#         f\"Val Loss: {avg_val_loss:.4f} (PPL {val_ppl:.2f})\"\n#     )\n\n#     if avg_val_loss < best_val_loss:\n#         best_val_loss = avg_val_loss\n#         wait = 0\n#         torch.save(model.state_dict(), \"best_model.pt\")\n#         print(\"  ** Validation improved, model saved.\")\n#     else:\n#         wait += 1\n#         print(f\"  ** No improvement ({wait}/{patience})\")\n\n#         if wait >= patience:\n#             print(\"Early stopping triggered.\")\n#             break\n\n# print(f\"Training finished. Best Validation Loss: {best_val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:04:14.469579Z","iopub.execute_input":"2025-12-25T05:04:14.469803Z","iopub.status.idle":"2025-12-25T05:04:14.480146Z","shell.execute_reply.started":"2025-12-25T05:04:14.469783Z","shell.execute_reply":"2025-12-25T05:04:14.479593Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# import math\n\n# def evaluate_model(model, dataloader, criterion, device):\n#     model.eval()  # set model to evaluation mode\n#     total_loss = 0\n#     total_correct = 0\n#     total_tokens = 0\n\n#     with torch.no_grad():  # no gradients needed for evaluation\n#         for x_batch, y_batch in dataloader:\n#             x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n#             logits, _ = model(x_batch)\n\n#             # compute loss\n#             loss = criterion(logits.view(-1, logits.size(-1)), y_batch.view(-1))\n#             total_loss += loss.item() * x_batch.size(0)  # multiply by batch size\n\n#             # compute token-level accuracy\n#             predictions = logits.argmax(dim=-1)\n#             total_correct += (predictions == y_batch).sum().item()\n#             total_tokens += y_batch.numel()\n\n#     avg_loss = total_loss / len(dataloader.dataset)\n#     perplexity = math.exp(avg_loss)\n#     accuracy = total_correct / total_tokens\n\n#     return avg_loss, perplexity, accuracy\n\n# # Usage\n# avg_loss, perplexity, accuracy = evaluate_model(model, test_loader, criterion, device)\n# print(f\"Test Loss: {avg_loss:.4f}\")\n# print(f\"Test Perplexity: {perplexity:.2f}\")\n# print(f\"Token-level Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:09:39.897796Z","iopub.execute_input":"2025-12-25T05:09:39.898624Z","iopub.status.idle":"2025-12-25T05:09:39.902234Z","shell.execute_reply.started":"2025-12-25T05:09:39.898592Z","shell.execute_reply":"2025-12-25T05:09:39.901378Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Recreate the model architecture\nmodel = LSTMTST(vocab_size).to(device)\n\n# Load the saved weights\nmodel.load_state_dict(torch.load(\"/kaggle/input/pretrained-lstm/pytorch/default/1/best_model.pt\", map_location=device))\n\n# Set model to evaluation mode\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:05:14.778746Z","iopub.execute_input":"2025-12-25T05:05:14.779042Z","iopub.status.idle":"2025-12-25T05:05:14.876930Z","shell.execute_reply.started":"2025-12-25T05:05:14.779014Z","shell.execute_reply":"2025-12-25T05:05:14.875675Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"LSTMTST(\n  (embedding): Embedding(95, 128)\n  (lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=256, out_features=95, bias=True)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"seed_text = \"ជ្រើសរើសជាតំណាងសាជីវកម្មហិរញ្ញវត្ថុអន្តរជាតិ ប្រចាំ កម្ពុជា\"\ntokens = [stoi[ch] for ch in seed_text if ch in stoi]\n\n# generate next 100 characters\ngenerated = tokens.copy()\nfor _ in range(100):\n    input_seq = torch.tensor([generated[-seq_len:]]).to(device)  # last seq_len tokens\n    logits, _ = model(input_seq)\n    next_token = logits[:, -1, :].argmax(dim=-1).item()\n    generated.append(next_token)\n\n# convert back to characters\ngenerated_text = \"\".join([itos[t] for t in generated])\nprint(generated_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T05:08:20.183832Z","iopub.execute_input":"2025-12-25T05:08:20.184125Z","iopub.status.idle":"2025-12-25T05:08:20.346761Z","shell.execute_reply.started":"2025-12-25T05:08:20.184101Z","shell.execute_reply":"2025-12-25T05:08:20.346165Z"}},"outputs":[{"name":"stdout","text":"ជ្រើសរើសជាតំណាងសាជីវកម្មហិរញ្ញវត្ថុអន្តរជាតិ ប្រចាំ កម្ពុជា និងថៃ បានប្រាប់ ថា នៅពេលនេះ គឺជាការប្រមូលផលដើមរបស់ សម្តេចមហាបវរធិបតី ហ៊ុន ម៉ាណែត នាយករដ្ឋមន្ត្រី នៃ\n","output_type":"stream"}],"execution_count":22}]}