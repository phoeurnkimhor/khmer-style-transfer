{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14267558,"sourceType":"datasetVersion","datasetId":9104670},{"sourceId":701914,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":532613,"modelId":546361}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport string\nimport random\nimport torch\nimport math\nimport os\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:37:31.216640Z","iopub.execute_input":"2025-12-29T01:37:31.217004Z","iopub.status.idle":"2025-12-29T01:37:38.752851Z","shell.execute_reply.started":"2025-12-29T01:37:31.216969Z","shell.execute_reply":"2025-12-29T01:37:38.751737Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\nif device == 'cuda':\n    torch.cuda.manual_seed_all(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:37:38.754514Z","iopub.execute_input":"2025-12-29T01:37:38.755004Z","iopub.status.idle":"2025-12-29T01:37:38.772410Z","shell.execute_reply.started":"2025-12-29T01:37:38.754966Z","shell.execute_reply":"2025-12-29T01:37:38.771364Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = []\nwith open(\"/kaggle/input/khmer-text/general-text.txt\") as f:\n    for i, line in enumerate(f, 1):\n        data.append({'text' : line.replace('\\n', '')})\n        \ndf = pd.DataFrame(data)\ndf.head()\nprint(df.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:37:38.773630Z","iopub.execute_input":"2025-12-29T01:37:38.774002Z","iopub.status.idle":"2025-12-29T01:37:41.438778Z","shell.execute_reply.started":"2025-12-29T01:37:38.773962Z","shell.execute_reply":"2025-12-29T01:37:41.437785Z"}},"outputs":[{"name":"stdout","text":"(582511, 1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df['text'] = df['text'].replace('', np.nan)\ndf.dropna(inplace=True)\nprint(df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:37:41.441254Z","iopub.execute_input":"2025-12-29T01:37:41.441576Z","iopub.status.idle":"2025-12-29T01:37:41.678686Z","shell.execute_reply.started":"2025-12-29T01:37:41.441545Z","shell.execute_reply":"2025-12-29T01:37:41.677741Z"}},"outputs":[{"name":"stdout","text":"(471632, 1)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import re\nimport string\n\nunwanted_chars = [\n    '\\u200b', '\\u200c', '\\u200d', '\\ufeff',\n    '៙', '៚', '៖', 'ៗ', '៛', '៝', '៸', '៓'\n]\n\nkhmer_punct = '។៕៘'\n\nreplace_map = {\n    'ឝ': 'គ',\n    'ឞ': 'ម',\n}\n\ndef clean_text(text):\n    text = ''.join(c for c in text if c not in unwanted_chars)\n    text = re.sub(r'[A-Za-z0-9]+', '', text)\n    text = ''.join(c for c in text if c not in string.punctuation)\n    text = re.sub(r'[^\\u1780-\\u17FF\\u17E0-\\u17E9\\s' + khmer_punct + ']', '', text)\n    for old, new in replace_map.items():\n        text = text.replace(old, new)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndf['text'] = df['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:37:41.679833Z","iopub.execute_input":"2025-12-29T01:37:41.680205Z","iopub.status.idle":"2025-12-29T01:38:05.492079Z","shell.execute_reply.started":"2025-12-29T01:37:41.680166Z","shell.execute_reply":"2025-12-29T01:38:05.491065Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:05.493226Z","iopub.execute_input":"2025-12-29T01:38:05.493500Z","iopub.status.idle":"2025-12-29T01:38:05.503369Z","shell.execute_reply.started":"2025-12-29T01:38:05.493476Z","shell.execute_reply":"2025-12-29T01:38:05.502342Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0         សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n2         យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...\n4         លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n6         គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n8         លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...\n                                ...                        \n582504    ដូចទៅនិង ភរិយាទីពីររបស់ ដែលត្រូវគាត់បោះបង់ចោលដ...\n582505    ទំនួលខុសត្រូវសង្គមរបស់ពួកគេគឺជាភាពស្មោះត្រង់ខា...\n582506    នេះតម្រូវឲ្យមានការគោរពដល់ឯកជនភាព កិត្តិយសរបស់ប...\n582507    យោងតាម ទាំងនេះគឺជាកត្តាដែលរារាំងដល់វិជ្ជាជីវៈស...\n582508                       គំនិតដ៏វៀងវៃគឺជាសម្បត្តិមហាសាល\nName: text, Length: 471632, dtype: object"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def tokenize(text):\n    return list(text)\n\nspecial_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\nunwanted_tokens = ['៘','។', '៕', '឴']\nall_text = df['text'].tolist()\ntokens = [t for sentence in all_text for t in tokenize(sentence) if t not in unwanted_tokens]\n\nvocab = sorted(set(tokens))\nvocab = vocab + special_tokens \nstoi = {ch: i for i, ch in enumerate(vocab)}\nitos = {i: ch for ch, i in stoi.items()}\n\nvocab_size = len(vocab)\nprint(vocab_size)\nprint(stoi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:05.504708Z","iopub.execute_input":"2025-12-29T01:38:05.505581Z","iopub.status.idle":"2025-12-29T01:38:14.490490Z","shell.execute_reply.started":"2025-12-29T01:38:05.505546Z","shell.execute_reply":"2025-12-29T01:38:14.489550Z"}},"outputs":[{"name":"stdout","text":"94\n{' ': 0, 'ក': 1, 'ខ': 2, 'គ': 3, 'ឃ': 4, 'ង': 5, 'ច': 6, 'ឆ': 7, 'ជ': 8, 'ឈ': 9, 'ញ': 10, 'ដ': 11, 'ឋ': 12, 'ឌ': 13, 'ឍ': 14, 'ណ': 15, 'ត': 16, 'ថ': 17, 'ទ': 18, 'ធ': 19, 'ន': 20, 'ប': 21, 'ផ': 22, 'ព': 23, 'ភ': 24, 'ម': 25, 'យ': 26, 'រ': 27, 'ល': 28, 'វ': 29, 'ស': 30, 'ហ': 31, 'ឡ': 32, 'អ': 33, 'ឣ': 34, 'ឤ': 35, 'ឥ': 36, 'ឦ': 37, 'ឧ': 38, 'ឩ': 39, 'ឪ': 40, 'ឫ': 41, 'ឬ': 42, 'ឭ': 43, 'ឮ': 44, 'ឯ': 45, 'ឰ': 46, 'ឱ': 47, 'ឲ': 48, 'ឳ': 49, '឵': 50, 'ា': 51, 'ិ': 52, 'ី': 53, 'ឹ': 54, 'ឺ': 55, 'ុ': 56, 'ូ': 57, 'ួ': 58, 'ើ': 59, 'ឿ': 60, 'ៀ': 61, 'េ': 62, 'ែ': 63, 'ៃ': 64, 'ោ': 65, 'ៅ': 66, 'ំ': 67, 'ះ': 68, 'ៈ': 69, '៉': 70, '៊': 71, '់': 72, '៌': 73, '៍': 74, '៎': 75, '៏': 76, '័': 77, '៑': 78, '្': 79, '០': 80, '១': 81, '២': 82, '៣': 83, '៤': 84, '៥': 85, '៦': 86, '៧': 87, '៨': 88, '៩': 89, '<pad>': 90, '<unk>': 91, '<sos>': 92, '<eos>': 93}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def split_sentences(text):\n    \"\"\"Split Khmer text into sentences based on punctuation\"\"\"\n    sentences = re.split(r'[។៕៘]', text)\n    return [s.strip() for s in sentences if s.strip()]\n\ndef chunk_text_recursive(sentence, chunk_size=150, overlap=50):\n    chunks = []\n    start = 0\n    while start < len(sentence):\n        end = start + chunk_size\n        chunks.append(sentence[start:end])\n        # Move start by (chunk_size - overlap)\n        start += chunk_size - overlap\n    return chunks\n\ndef sentence_to_char_indices(sentence, vocab):\n    \"\"\"Convert sentence to list of token indices with <sos> and <eos>\"\"\"\n    chars = list(sentence)\n    return [vocab[\"<sos>\"]] + [vocab.get(c, vocab[\"<unk>\"]) for c in chars] + [vocab[\"<eos>\"]]\n\ndef prepare_dataset(texts, vocab, chunk_size=150, overlap=50):\n    inputs, targets = [], []\n    for text in texts:     \n        sentences = split_sentences(text)\n        for sent in sentences:\n            chunks = chunk_text_recursive(sent, chunk_size, overlap)\n            for chunk in chunks:\n                ids = sentence_to_char_indices(chunk, vocab)\n                inputs.append(ids[:-1])\n                targets.append(ids[1:])\n    return inputs, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:14.491591Z","iopub.execute_input":"2025-12-29T01:38:14.491869Z","iopub.status.idle":"2025-12-29T01:38:14.501378Z","shell.execute_reply.started":"2025-12-29T01:38:14.491834Z","shell.execute_reply":"2025-12-29T01:38:14.500421Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_clean = df[df['text'].str.strip().astype(bool)]\ndf_clean = df_clean[df_clean['text'].str.len() >= 120]\n\n# Randomly select 30,000 rows\ndf_sample = df_clean.sample(n=30000, random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:14.502632Z","iopub.execute_input":"2025-12-29T01:38:14.502986Z","iopub.status.idle":"2025-12-29T01:38:14.826677Z","shell.execute_reply.started":"2025-12-29T01:38:14.502933Z","shell.execute_reply":"2025-12-29T01:38:14.825542Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_texts, temp_texts = train_test_split(df_sample['text'].tolist(), test_size=0.2, random_state=seed)\nval_texts, test_texts = train_test_split(temp_texts, test_size=0.5, random_state=seed)\n\nX_train, Y_train = prepare_dataset(train_texts, stoi)\nX_val, Y_val = prepare_dataset(val_texts, stoi)\nX_test, Y_test = prepare_dataset(test_texts, stoi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:14.829599Z","iopub.execute_input":"2025-12-29T01:38:14.829909Z","iopub.status.idle":"2025-12-29T01:38:20.802655Z","shell.execute_reply.started":"2025-12-29T01:38:14.829880Z","shell.execute_reply":"2025-12-29T01:38:20.801461Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def decode_ids_to_text(ids, itos, remove_special_tokens=True):\n    \"\"\"Convert a list of token IDs back into readable text.\"\"\"\n    tokens = [itos[i] for i in ids if i in itos]\n    \n    if remove_special_tokens:\n        tokens = [t for t in tokens if t not in (\"<sos>\", \"<eos>\", \"<pad>\", \"<unk>\")]\n    \n    return \"\".join(tokens)\n\nids = Y_train[0]\nprint(ids)\ndecoded_text = decode_ids_to_text(ids, itos)\nprint(decoded_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:20.803997Z","iopub.execute_input":"2025-12-29T01:38:20.804296Z","iopub.status.idle":"2025-12-29T01:38:20.811742Z","shell.execute_reply.started":"2025-12-29T01:38:20.804269Z","shell.execute_reply":"2025-12-29T01:38:20.810525Z"}},"outputs":[{"name":"stdout","text":"[33, 51, 6, 21, 5, 79, 1, 47, 79, 26, 25, 51, 20, 1, 57, 20, 25, 52, 20, 3, 79, 27, 21, 72, 2, 63, 0, 18, 51, 27, 1, 1, 59, 16, 25, 1, 25, 51, 20, 18, 25, 79, 5, 20, 72, 18, 51, 21, 0, 21, 10, 79, 31, 51, 20, 62, 68, 20, 54, 5, 21, 20, 79, 30, 28, 72, 18, 56, 1, 20, 57, 29, 22, 28, 29, 52, 21, 51, 1, 19, 79, 5, 20, 72, 19, 79, 5, 27, 8, 51, 6, 79, 27, 59, 20, 6, 67, 23, 65, 68, 18, 51, 27, 1, 11, 57, 6, 8, 51, 1, 79, 27, 52, 20, 0, 1, 5, 79, 29, 68, 33, 51, 31, 51, 27, 57, 21, 16, 79, 17, 25, 79, 24, 0, 2, 79, 30, 65, 26, 22, 79, 28, 57, 29, 11, 5, 79, 31, 59, 25, 93]\nអាចបង្កឱ្យមានកូនមិនគ្រប់ខែ ទារកកើតមកមានទម្ងន់ទាប បញ្ហានេះនឹងបន្សល់ទុកនូវផលវិបាកធ្ងន់ធ្ងរជាច្រើនចំពោះទារកដូចជាក្រិន កង្វះអាហារូបត្ថម្ភ ខ្សោយផ្លូវដង្ហើម\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class CharDataset(Dataset):\n    def __init__(self, inputs, targets):\n        self.inputs = inputs\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=stoi[\"<pad>\"])\n    targets_padded = pad_sequence(targets, batch_first=True, padding_value=stoi[\"<pad>\"])\n    return inputs_padded, targets_padded\n\nbatch_size = 32\ntrain_dataset = CharDataset(X_train, Y_train)\nval_dataset = CharDataset(X_val, Y_val)\ntest_dataset = CharDataset(X_test, Y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n\nfor x, y in train_loader:\n    print(\"Input batch shape:\", x.shape)\n    print(\"Target batch shape:\", y.shape)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:20.812997Z","iopub.execute_input":"2025-12-29T01:38:20.813317Z","iopub.status.idle":"2025-12-29T01:38:20.956093Z","shell.execute_reply.started":"2025-12-29T01:38:20.813287Z","shell.execute_reply":"2025-12-29T01:38:20.955087Z"}},"outputs":[{"name":"stdout","text":"Input batch shape: torch.Size([32, 151])\nTarget batch shape: torch.Size([32, 151])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class LSTMAutoencoder(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.encoder = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.decoder = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden=None):\n        emb = self.embedding(x)\n        enc_out, enc_hidden = self.encoder(emb)\n        dec_out, dec_hidden = self.decoder(emb, enc_hidden)\n        logits = self.fc(dec_out)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:20.957150Z","iopub.execute_input":"2025-12-29T01:38:20.957450Z","iopub.status.idle":"2025-12-29T01:38:20.964780Z","shell.execute_reply.started":"2025-12-29T01:38:20.957421Z","shell.execute_reply":"2025-12-29T01:38:20.963551Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"save_dir = \"/kaggle/working/checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\n\n# Initialize model, optimizer, loss\nmodel = LSTMAutoencoder(vocab_size=len(stoi)).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=stoi[\"<pad>\"])\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nepochs = 20\npatience = 3\nbest_val_loss = float('inf')\nwait = 0\n\nfor epoch in range(epochs):\n\n    # ---- Training Phase ----\n    model.train()\n    total_train_loss = 0\n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n\n    for x_batch, y_batch in train_bar:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model(x_batch)  # only returns logits\n        loss = criterion(logits.reshape(-1, logits.size(-1)), y_batch.reshape(-1))\n        loss.backward()\n\n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n        optimizer.step()\n\n        total_train_loss += loss.item()\n        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_ppl = math.exp(avg_train_loss)\n\n    # ---- Validation Phase ----\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for x_batch, y_batch in val_loader:\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n            logits = model(x_batch)  # FIXED (no unpacking)\n            loss = criterion(logits.reshape(-1, logits.size(-1)), y_batch.reshape(-1))\n            total_val_loss += loss.item()\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    val_ppl = math.exp(avg_val_loss)\n\n    # ---- Logging ----\n    print(f\"Epoch {epoch+1}/{epochs} | \"\n          f\"Train Loss: {avg_train_loss:.4f} (PPL {train_ppl:.4f}) | \"\n          f\"Val Loss: {avg_val_loss:.4f} (PPL {val_ppl:.4f})\")\n\n    # ---- Checkpointing ----\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        wait = 0\n\n        save_path = os.path.join(save_dir, \"best_autoencoder.pt\")\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'vocab_size': len(stoi),\n            'stoi': stoi,\n            'itos': itos,\n            'embedding_dim': 128,\n            'hidden_dim': 256,\n            'num_layers': 2,\n            'best_val_loss': best_val_loss,\n            'epoch': epoch + 1\n        }, save_path)\n\n        print(f\"  ** Validation improved, model saved to {save_path}\")\n    else:\n        wait += 1\n        print(f\"  ** No improvement ({wait}/{patience})\")\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\nprint(f\"Training finished. Best Validation Loss: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:20.966135Z","iopub.execute_input":"2025-12-29T01:38:20.966636Z","iopub.status.idle":"2025-12-29T01:38:20.987403Z","shell.execute_reply.started":"2025-12-29T01:38:20.966603Z","shell.execute_reply":"2025-12-29T01:38:20.986419Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"checkpoint = torch.load(\"/kaggle/input/best/pytorch/default/1/best_autoencoder.pt\", map_location=\"cpu\")\nstoi = checkpoint[\"stoi\"]\nitos = checkpoint[\"itos\"]\n\nmodel = LSTMAutoencoder(\n    vocab_size=checkpoint[\"vocab_size\"],\n    embed_dim=checkpoint[\"embedding_dim\"],   \n    hidden_dim=checkpoint[\"hidden_dim\"],\n    num_layers=checkpoint[\"num_layers\"]\n)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:20.988388Z","iopub.execute_input":"2025-12-29T01:38:20.988660Z","iopub.status.idle":"2025-12-29T01:38:21.370885Z","shell.execute_reply.started":"2025-12-29T01:38:20.988635Z","shell.execute_reply":"2025-12-29T01:38:21.370053Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"LSTMAutoencoder(\n  (embedding): Embedding(94, 128)\n  (encoder): LSTM(128, 256, num_layers=2, batch_first=True)\n  (decoder): LSTM(128, 256, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=256, out_features=94, bias=True)\n)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for x_batch, _ in test_loader:  # targets are same as input for autoencoder\n        x_batch = x_batch.to(device)\n        logits = model(x_batch)  # [batch, seq_len, vocab_size]\n        pred_ids = logits.argmax(dim=-1)\n        predictions.extend(pred_ids.cpu().tolist())\n\n\nsmoothie = SmoothingFunction().method4\ntotal_bleu = 0\n\nfor pred_ids, target_ids in zip(predictions, X_test):  # X_test = input sequences\n    pred_chars = [itos[idx] for idx in pred_ids if idx not in (stoi['<pad>'],)]\n    target_chars = [itos[idx] for idx in target_ids if idx not in (stoi['<pad>'],)]\n    total_bleu += sentence_bleu([target_chars], pred_chars, smoothing_function=smoothie)\n\navg_bleu = total_bleu / len(predictions)\nprint(f\"Pre-trained model char-level BLEU: {avg_bleu:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T01:38:21.372171Z","iopub.execute_input":"2025-12-29T01:38:21.372427Z","iopub.status.idle":"2025-12-29T01:40:01.453681Z","shell.execute_reply.started":"2025-12-29T01:38:21.372404Z","shell.execute_reply":"2025-12-29T01:40:01.452651Z"}},"outputs":[{"name":"stdout","text":"Pre-trained model char-level BLEU: 0.3089\n","output_type":"stream"}],"execution_count":16}]}