{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14267558,"sourceType":"datasetVersion","datasetId":9104670}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport string\n\ndata = []\nwith open(\"/kaggle/input/khmer-text/general-text.txt\") as f:\n    for i, line in enumerate(f, 1):\n        data.append({'text' : line.replace('\\n', '')})\n        \ndf = pd.DataFrame(data)\ndf.head()\nprint(df.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:25.766842Z","iopub.execute_input":"2025-12-27T08:10:25.767074Z","iopub.status.idle":"2025-12-27T08:10:30.125187Z","shell.execute_reply.started":"2025-12-27T08:10:25.767052Z","shell.execute_reply":"2025-12-27T08:10:30.124550Z"}},"outputs":[{"name":"stdout","text":"(582511, 1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\ndf['text'] = df['text'].replace('', np.nan)\ndf.dropna(inplace=True)\nprint(df.shape)\ndf.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:30.126813Z","iopub.execute_input":"2025-12-27T08:10:30.127149Z","iopub.status.idle":"2025-12-27T08:10:30.359410Z","shell.execute_reply.started":"2025-12-27T08:10:30.127125Z","shell.execute_reply":"2025-12-27T08:10:30.358694Z"}},"outputs":[{"name":"stdout","text":"(471632, 1)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...\n4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import re\nimport string\n\nunwanted_chars = ['\\u200b','\\u200c','\\u200d','\\ufeff','៙','៚','៖','ៗ','៛']\n\nkhmer_punct = '។៕'\n\ndef clean_text(text):\n    text = ''.join(c for c in text if c not in unwanted_chars)\n    text = re.sub(r'[A-Za-z0-9]+', '', text)\n    allowed_chars = string.ascii_letters + string.digits\n    text = ''.join(c for c in text if c not in string.punctuation)\n    text = re.sub(r'[^\\u1780-\\u17FF\\u17E0-\\u17E9\\s' + khmer_punct + ']', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\ndf['text'] = df['text'].apply(clean_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:30.360398Z","iopub.execute_input":"2025-12-27T08:10:30.360655Z","iopub.status.idle":"2025-12-27T08:10:47.899772Z","shell.execute_reply.started":"2025-12-27T08:10:30.360632Z","shell.execute_reply":"2025-12-27T08:10:47.898978Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:47.900757Z","iopub.execute_input":"2025-12-27T08:10:47.901028Z","iopub.status.idle":"2025-12-27T08:10:47.907832Z","shell.execute_reply.started":"2025-12-27T08:10:47.900999Z","shell.execute_reply":"2025-12-27T08:10:47.907167Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...\n4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def split_sentences(text):\n    sentences = re.split(r'[។៕]', text)\n    return [s.strip() for s in sentences if s.strip()]\n\ndf['sentences'] = df['text'].apply(split_sentences)\n\ndef chunk_text(sentence, chunk_size=120):\n    return [sentence[i:i + chunk_size] for i in range(0, len(sentence), chunk_size)]\n\ndf['chunks'] = df['sentences'].apply(lambda sents: [chunk for sent in sents for chunk in chunk_text(sent)])\n\ndf_exploded = df.explode('chunks', ignore_index=True)\ndf_exploded = df_exploded[df_exploded['chunks'].notna() & (df_exploded['chunks'] != '')]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:47.908701Z","iopub.execute_input":"2025-12-27T08:10:47.909032Z","iopub.status.idle":"2025-12-27T08:10:50.382131Z","shell.execute_reply.started":"2025-12-27T08:10:47.909011Z","shell.execute_reply":"2025-12-27T08:10:50.381463Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_new = pd.DataFrame({\n    'sentence': df_exploded['chunks'],\n    'target': df_exploded['chunks']\n})\n\ndf_new = df_new.iloc[:100000, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:50.383049Z","iopub.execute_input":"2025-12-27T08:10:50.383344Z","iopub.status.idle":"2025-12-27T08:10:50.410577Z","shell.execute_reply.started":"2025-12-27T08:10:50.383308Z","shell.execute_reply":"2025-12-27T08:10:50.409851Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom collections import Counter\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:10:50.412662Z","iopub.execute_input":"2025-12-27T08:10:50.412974Z","iopub.status.idle":"2025-12-27T08:10:56.735332Z","shell.execute_reply.started":"2025-12-27T08:10:50.412950Z","shell.execute_reply":"2025-12-27T08:10:56.734665Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def tokenize(text):\n    return list(text)\n\nspecial_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n\nall_text = df_new['sentence'].tolist()\ntokens = [t for sentence in all_text for t in tokenize(sentence)]\ntokens = tokens + special_tokens\n\nvocab = sorted(set(tokens))\nstoi = {ch: i for i, ch in enumerate(vocab)}\nitos = {i: ch for ch, i in stoi.items()}\n\nvocab_size = len(vocab)\nprint(vocab_size)\nprint(stoi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T08:12:27.054640Z","iopub.execute_input":"2025-12-27T08:12:27.055318Z","iopub.status.idle":"2025-12-27T08:12:28.282998Z","shell.execute_reply.started":"2025-12-27T08:12:27.055288Z","shell.execute_reply":"2025-12-27T08:12:28.282379Z"}},"outputs":[{"name":"stdout","text":"95\n{' ': 0, '<eos>': 1, '<pad>': 2, '<sos>': 3, '<unk>': 4, 'ក': 5, 'ខ': 6, 'គ': 7, 'ឃ': 8, 'ង': 9, 'ច': 10, 'ឆ': 11, 'ជ': 12, 'ឈ': 13, 'ញ': 14, 'ដ': 15, 'ឋ': 16, 'ឌ': 17, 'ឍ': 18, 'ណ': 19, 'ត': 20, 'ថ': 21, 'ទ': 22, 'ធ': 23, 'ន': 24, 'ប': 25, 'ផ': 26, 'ព': 27, 'ភ': 28, 'ម': 29, 'យ': 30, 'រ': 31, 'ល': 32, 'វ': 33, 'ឝ': 34, 'ឞ': 35, 'ស': 36, 'ហ': 37, 'ឡ': 38, 'អ': 39, 'ឣ': 40, 'ឤ': 41, 'ឥ': 42, 'ឦ': 43, 'ឧ': 44, 'ឩ': 45, 'ឪ': 46, 'ឫ': 47, 'ឬ': 48, 'ឭ': 49, 'ឮ': 50, 'ឯ': 51, 'ឰ': 52, 'ឱ': 53, 'ឲ': 54, 'ឳ': 55, 'ា': 56, 'ិ': 57, 'ី': 58, 'ឹ': 59, 'ឺ': 60, 'ុ': 61, 'ូ': 62, 'ួ': 63, 'ើ': 64, 'ឿ': 65, 'ៀ': 66, 'េ': 67, 'ែ': 68, 'ៃ': 69, 'ោ': 70, 'ៅ': 71, 'ំ': 72, 'ះ': 73, 'ៈ': 74, '៉': 75, '៊': 76, '់': 77, '៌': 78, '៍': 79, '៏': 80, '័': 81, '៑': 82, '្': 83, '៝': 84, '០': 85, '១': 86, '២': 87, '៣': 88, '៤': 89, '៥': 90, '៦': 91, '៧': 92, '៨': 93, '៩': 94}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def sentence_to_char_indices(sentence, vocab):\n    chars = list(sentence)\n    return [vocab[\"<sos>\"]] + [vocab.get(c, vocab[\"<unk>\"]) for c in chars] + [vocab[\"<eos>\"]]\n\ndf['input_ids'] = df['normal'].apply(lambda s: sentence_to_char_indices(s, vocab))\ndf['target_ids'] = df['royal'].apply(lambda s: sentence_to_char_indices(s, vocab))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclass LSTMTST(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden=None):\n        emb = self.embedding(x)\n        out, hidden = self.lstm(emb, hidden)\n        logits = self.fc(out)\n        return logits, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T04:26:17.732276Z","iopub.execute_input":"2025-12-27T04:26:17.732578Z","iopub.status.idle":"2025-12-27T04:26:17.738478Z","shell.execute_reply.started":"2025-12-27T04:26:17.732553Z","shell.execute_reply":"2025-12-27T04:26:17.737785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport math\nfrom tqdm import tqdm\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = LSTMTST(vocab_size).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nepochs = 20\npatience = 3  # stop after 3 epochs with no improvement\nbest_val_loss = float('inf')\nwait = 0  \n\nfor epoch in range(epochs):\n    model.train()\n    total_train_loss = 0\n\n    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n    for x_batch, y_batch in train_bar:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits, _ = model(x_batch)\n        loss = criterion(logits.reshape(-1, vocab_size), y_batch.reshape(-1))\n        loss.backward()\n        optimizer.step()\n\n        total_train_loss += loss.item()\n        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_ppl = math.exp(avg_train_loss)\n\n    model.eval()\n    total_val_loss = 0\n    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n    with torch.no_grad():\n        for x_batch, y_batch in val_bar:\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n            logits, _ = model(x_batch)\n            loss = criterion(logits.reshape(-1, vocab_size), y_batch.reshape(-1))\n            total_val_loss += loss.item()\n            val_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    val_ppl = math.exp(avg_val_loss)\n\n    print(\n        f\"Epoch {epoch+1}/{epochs} | \"\n        f\"Train Loss: {avg_train_loss:.4f} (PPL {train_ppl:.2f}) | \"\n        f\"Val Loss: {avg_val_loss:.4f} (PPL {val_ppl:.2f})\"\n    )\n\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        wait = 0\n        torch.save(model.state_dict(), \"best_model.pt\")\n        print(\"  ** Validation improved, model saved.\")\n    else:\n        wait += 1\n        print(f\"  ** No improvement ({wait}/{patience})\")\n\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\nprint(f\"Training finished. Best Validation Loss: {best_val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T04:26:17.739418Z","iopub.execute_input":"2025-12-27T04:26:17.739641Z","iopub.status.idle":"2025-12-27T04:27:44.398631Z","shell.execute_reply.started":"2025-12-27T04:26:17.739620Z","shell.execute_reply":"2025-12-27T04:27:44.397716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef evaluate_model(model, dataloader, criterion, device):\n    model.eval()  # set model to evaluation mode\n    total_loss = 0\n    total_correct = 0\n    total_tokens = 0\n\n    with torch.no_grad():  # no gradients needed for evaluation\n        for x_batch, y_batch in dataloader:\n            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n            logits, _ = model(x_batch)\n\n            # compute loss\n            loss = criterion(logits.view(-1, logits.size(-1)), y_batch.view(-1))\n            total_loss += loss.item() * x_batch.size(0)  # multiply by batch size\n\n            # compute token-level accuracy\n            predictions = logits.argmax(dim=-1)\n            total_correct += (predictions == y_batch).sum().item()\n            total_tokens += y_batch.numel()\n\n    avg_loss = total_loss / len(dataloader.dataset)\n    perplexity = math.exp(avg_loss)\n    accuracy = total_correct / total_tokens\n\n    return avg_loss, perplexity, accuracy\n\n# Usage\navg_loss, perplexity, accuracy = evaluate_model(model, test_loader, criterion, device)\nprint(f\"Test Loss: {avg_loss:.4f}\")\nprint(f\"Test Perplexity: {perplexity:.2f}\")\nprint(f\"Token-level Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T04:27:44.399462Z","iopub.status.idle":"2025-12-27T04:27:44.399845Z","shell.execute_reply.started":"2025-12-27T04:27:44.399642Z","shell.execute_reply":"2025-12-27T04:27:44.399666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# # Recreate the model architecture\n# model = LSTMTST(vocab_size).to(device)\n\n# # Load the saved weights\n# model.load_state_dict(torch.load(\"/kaggle/input/pretrained-lstm/pytorch/default/1/best_model.pt\", map_location=device))\n\n# # Set model to evaluation mode\n# model.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T04:27:44.401360Z","iopub.status.idle":"2025-12-27T04:27:44.401683Z","shell.execute_reply.started":"2025-12-27T04:27:44.401511Z","shell.execute_reply":"2025-12-27T04:27:44.401541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed_text = \"គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ\"\ntokens = [stoi[ch] for ch in seed_text if ch in stoi]\n\n# generate next 100 characters\ngenerated = tokens.copy()\nfor _ in range(100):\n    input_seq = torch.tensor([generated[-seq_len:]]).to(device)  # last seq_len tokens\n    logits, _ = model(input_seq)\n    next_token = logits[:, -1, :].argmax(dim=-1).item()\n    generated.append(next_token)\n\n# convert back to characters\ngenerated_text = \"\".join([itos[t] for t in generated])\nprint(generated_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T04:27:44.402850Z","iopub.status.idle":"2025-12-27T04:27:44.403159Z","shell.execute_reply.started":"2025-12-27T04:27:44.402994Z","shell.execute_reply":"2025-12-27T04:27:44.403014Z"}},"outputs":[],"execution_count":null}]}