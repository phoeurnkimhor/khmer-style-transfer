{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f353a84",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:21.086816Z",
     "iopub.status.busy": "2025-12-27T04:32:21.086553Z",
     "iopub.status.idle": "2025-12-27T04:32:24.330688Z",
     "shell.execute_reply": "2025-12-27T04:32:24.329929Z"
    },
    "papermill": {
     "duration": 3.25016,
     "end_time": "2025-12-27T04:32:24.332506",
     "exception": false,
     "start_time": "2025-12-27T04:32:21.082346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(582511, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "data = []\n",
    "with open(\"/kaggle/input/khmer-text/general-text.txt\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        data.append({'text' : line.replace('\\n', '')})\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213cf569",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:24.339722Z",
     "iopub.status.busy": "2025-12-27T04:32:24.338994Z",
     "iopub.status.idle": "2025-12-27T04:32:24.549683Z",
     "shell.execute_reply": "2025-12-27T04:32:24.548923Z"
    },
    "papermill": {
     "duration": 0.216055,
     "end_time": "2025-12-27T04:32:24.551478",
     "exception": false,
     "start_time": "2025-12-27T04:32:24.335423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471632, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n",
       "2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង, បងប្អ...\n",
       "4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n",
       "6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n",
       "8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាល​ខេត្តសៀមរា..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['text'] = df['text'].replace('', np.nan)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837d26ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:24.558765Z",
     "iopub.status.busy": "2025-12-27T04:32:24.558497Z",
     "iopub.status.idle": "2025-12-27T04:32:42.974954Z",
     "shell.execute_reply": "2025-12-27T04:32:42.974009Z"
    },
    "papermill": {
     "duration": 18.422248,
     "end_time": "2025-12-27T04:32:42.976902",
     "exception": false,
     "start_time": "2025-12-27T04:32:24.554654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "unwanted_chars = ['\\u200b','\\u200c','\\u200d','\\ufeff','៙','៚','៖','ៗ','៛']\n",
    "\n",
    "khmer_punct = '។៕'\n",
    "\n",
    "def clean_text(text):\n",
    "    text = ''.join(c for c in text if c not in unwanted_chars)\n",
    "    text = re.sub(r'[A-Za-z0-9]+', '', text)\n",
    "    allowed_chars = string.ascii_letters + string.digits\n",
    "    text = ''.join(c for c in text if c not in string.punctuation)\n",
    "    text = re.sub(r'[^\\u1780-\\u17FF\\u17E0-\\u17E9\\s' + khmer_punct + ']', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5dcb8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:42.983393Z",
     "iopub.status.busy": "2025-12-27T04:32:42.983104Z",
     "iopub.status.idle": "2025-12-27T04:32:42.990506Z",
     "shell.execute_reply": "2025-12-27T04:32:42.989832Z"
    },
    "papermill": {
     "duration": 0.012381,
     "end_time": "2025-12-27T04:32:42.992048",
     "exception": false,
     "start_time": "2025-12-27T04:32:42.979667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  សាលារាជធានីថា មិនទាន់ទទួលបាន លិខិតសុំធ្វើបាតុក...\n",
       "2  យប់នេះប៉ូលិសដាក់ប៉ុស្តិ៍រហូតដល់ ៧កន្លែង បងប្អូ...\n",
       "4  លោកស្រី ឃួន សុដារី អនុប្រធានកាកបាទក្រហមកម្ពុជា...\n",
       "6  គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ១៥ ខែកុម្ភៈម...\n",
       "8  លោក ហ៊ុន ម៉ានី ជួបប្រជុំជាមួយអភិបាលខេត្តសៀមរាប..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4658463b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:42.999306Z",
     "iopub.status.busy": "2025-12-27T04:32:42.998825Z",
     "iopub.status.idle": "2025-12-27T04:32:45.568054Z",
     "shell.execute_reply": "2025-12-27T04:32:45.567408Z"
    },
    "papermill": {
     "duration": 2.574764,
     "end_time": "2025-12-27T04:32:45.569936",
     "exception": false,
     "start_time": "2025-12-27T04:32:42.995172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    sentences = re.split(r'[។៕]', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "df['sentences'] = df['text'].apply(split_sentences)\n",
    "\n",
    "def chunk_text(sentence, chunk_size=120):\n",
    "    return [sentence[i:i + chunk_size] for i in range(0, len(sentence), chunk_size)]\n",
    "\n",
    "df['chunks'] = df['sentences'].apply(lambda sents: [chunk for sent in sents for chunk in chunk_text(sent)])\n",
    "\n",
    "df_exploded = df.explode('chunks', ignore_index=True)\n",
    "df_exploded = df_exploded[df_exploded['chunks'].notna() & (df_exploded['chunks'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03062353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:45.576674Z",
     "iopub.status.busy": "2025-12-27T04:32:45.576463Z",
     "iopub.status.idle": "2025-12-27T04:32:45.602589Z",
     "shell.execute_reply": "2025-12-27T04:32:45.601869Z"
    },
    "papermill": {
     "duration": 0.031532,
     "end_time": "2025-12-27T04:32:45.604278",
     "exception": false,
     "start_time": "2025-12-27T04:32:45.572746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({\n",
    "    'sentence': df_exploded['chunks'],\n",
    "    'target': df_exploded['chunks']\n",
    "})\n",
    "\n",
    "df_new = df_new.iloc[:100000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20fc9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:45.611040Z",
     "iopub.status.busy": "2025-12-27T04:32:45.610547Z",
     "iopub.status.idle": "2025-12-27T04:32:49.159405Z",
     "shell.execute_reply": "2025-12-27T04:32:49.158782Z"
    },
    "papermill": {
     "duration": 3.554084,
     "end_time": "2025-12-27T04:32:49.161253",
     "exception": false,
     "start_time": "2025-12-27T04:32:45.607169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62348ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:49.169435Z",
     "iopub.status.busy": "2025-12-27T04:32:49.168812Z",
     "iopub.status.idle": "2025-12-27T04:32:50.144428Z",
     "shell.execute_reply": "2025-12-27T04:32:50.143527Z"
    },
    "papermill": {
     "duration": 0.981535,
     "end_time": "2025-12-27T04:32:50.145944",
     "exception": false,
     "start_time": "2025-12-27T04:32:49.164409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "[' ', 'ក', 'ខ', 'គ', 'ឃ', 'ង', 'ច', 'ឆ', 'ជ', 'ឈ', 'ញ', 'ដ', 'ឋ', 'ឌ', 'ឍ', 'ណ', 'ត', 'ថ', 'ទ', 'ធ', 'ន', 'ប', 'ផ', 'ព', 'ភ', 'ម', 'យ', 'រ', 'ល', 'វ', 'ឝ', 'ឞ', 'ស', 'ហ', 'ឡ', 'អ', 'ឣ', 'ឤ', 'ឥ', 'ឦ', 'ឧ', 'ឩ', 'ឪ', 'ឫ', 'ឬ', 'ឭ', 'ឮ', 'ឯ', 'ឰ', 'ឱ', 'ឲ', 'ឳ', 'ា', 'ិ', 'ី', 'ឹ', 'ឺ', 'ុ', 'ូ', 'ួ', 'ើ', 'ឿ', 'ៀ', 'េ', 'ែ', 'ៃ', 'ោ', 'ៅ', 'ំ', 'ះ', 'ៈ', '៉', '៊', '់', '៌', '៍', '៏', '័', '៑', '្', '៝', '០', '១', '២', '៣', '៤', '៥', '៦', '៧', '៨', '៩']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "all_text = df_new['sentence'].tolist()\n",
    "tokens = [t for sentence in all_text for t in tokenize(sentence)]\n",
    "vocab = sorted(set(tokens))\n",
    "stoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dddfb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:32:50.153651Z",
     "iopub.status.busy": "2025-12-27T04:32:50.153068Z",
     "iopub.status.idle": "2025-12-27T04:33:15.659983Z",
     "shell.execute_reply": "2025-12-27T04:33:15.659192Z"
    },
    "papermill": {
     "duration": 25.512362,
     "end_time": "2025-12-27T04:33:15.661636",
     "exception": false,
     "start_time": "2025-12-27T04:32:50.149274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3680000\n",
      "Val samples: 430441\n",
      "Test samples: 416871\n"
     ]
    }
   ],
   "source": [
    "class TSTDataset(Dataset):\n",
    "    def __init__(self, texts, seq_len=50):\n",
    "        self.seq_len = seq_len\n",
    "        self.data = []\n",
    "        for sentence in texts:\n",
    "            token_ids = [stoi[ch] for ch in tokenize(sentence) if ch in stoi]\n",
    "            for i in range(len(token_ids) - seq_len):\n",
    "                self.data.append((token_ids[i:i+seq_len], token_ids[i+1:i+seq_len+1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "seq_len = 50\n",
    "batch_size = 64\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1  # must sum to 1.0\n",
    "\n",
    "n_total = len(all_text)\n",
    "train_end = int(n_total * train_ratio)\n",
    "val_end = train_end + int(n_total * val_ratio)\n",
    "\n",
    "train_texts = all_text[:train_end]\n",
    "val_texts = all_text[train_end:val_end]\n",
    "test_texts = all_text[val_end:]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TSTDataset(train_texts, seq_len=seq_len)\n",
    "val_dataset = TSTDataset(val_texts, seq_len=seq_len)\n",
    "test_dataset = TSTDataset(test_texts, seq_len=seq_len)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2acca8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:33:15.669224Z",
     "iopub.status.busy": "2025-12-27T04:33:15.668698Z",
     "iopub.status.idle": "2025-12-27T04:33:15.673752Z",
     "shell.execute_reply": "2025-12-27T04:33:15.673170Z"
    },
    "papermill": {
     "duration": 0.010396,
     "end_time": "2025-12-27T04:33:15.675065",
     "exception": false,
     "start_time": "2025-12-27T04:33:15.664669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMTST(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        emb = self.embedding(x)\n",
    "        out, hidden = self.lstm(emb, hidden)\n",
    "        logits = self.fc(out)\n",
    "        return logits, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "295748de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T04:33:15.681815Z",
     "iopub.status.busy": "2025-12-27T04:33:15.681581Z",
     "iopub.status.idle": "2025-12-27T05:23:27.904829Z",
     "shell.execute_reply": "2025-12-27T05:23:27.904167Z"
    },
    "papermill": {
     "duration": 3023.507794,
     "end_time": "2025-12-27T05:23:39.185786",
     "exception": false,
     "start_time": "2025-12-27T04:33:15.677992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 1.0398 (PPL 2.83) | Val Loss: 1.1369 (PPL 3.12)\n",
      "  ** Validation improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 0.9216 (PPL 2.51) | Val Loss: 1.1450 (PPL 3.14)\n",
      "  ** No improvement (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 0.8986 (PPL 2.46) | Val Loss: 1.1534 (PPL 3.17)\n",
      "  ** No improvement (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 0.8875 (PPL 2.43) | Val Loss: 1.1572 (PPL 3.18)\n",
      "  ** No improvement (3/3)\n",
      "Early stopping triggered.\n",
      "Training finished. Best Validation Loss: 1.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LSTMTST(vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "patience = 3  # stop after 3 epochs with no improvement\n",
    "best_val_loss = float('inf')\n",
    "wait = 0  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "    for x_batch, y_batch in train_bar:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(x_batch)\n",
    "        loss = criterion(logits.reshape(-1, vocab_size), y_batch.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_ppl = math.exp(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_bar:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits, _ = model(x_batch)\n",
    "            loss = criterion(logits.reshape(-1, vocab_size), y_batch.reshape(-1))\n",
    "            total_val_loss += loss.item()\n",
    "            val_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_ppl = math.exp(avg_val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f} (PPL {train_ppl:.2f}) | \"\n",
    "        f\"Val Loss: {avg_val_loss:.4f} (PPL {val_ppl:.2f})\"\n",
    "    )\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"  ** Validation improved, model saved.\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f\"  ** No improvement ({wait}/{patience})\")\n",
    "\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"Training finished. Best Validation Loss: {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4037f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T05:24:03.071579Z",
     "iopub.status.busy": "2025-12-27T05:24:03.070656Z",
     "iopub.status.idle": "2025-12-27T05:24:35.544881Z",
     "shell.execute_reply": "2025-12-27T05:24:35.544108Z"
    },
    "papermill": {
     "duration": 44.333858,
     "end_time": "2025-12-27T05:24:35.546565",
     "exception": false,
     "start_time": "2025-12-27T05:23:51.212707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1924\n",
      "Test Perplexity: 3.29\n",
      "Token-level Accuracy: 0.6778\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.no_grad():  # no gradients needed for evaluation\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits, _ = model(x_batch)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y_batch.view(-1))\n",
    "            total_loss += loss.item() * x_batch.size(0)  # multiply by batch size\n",
    "\n",
    "            # compute token-level accuracy\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            total_correct += (predictions == y_batch).sum().item()\n",
    "            total_tokens += y_batch.numel()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    accuracy = total_correct / total_tokens\n",
    "\n",
    "    return avg_loss, perplexity, accuracy\n",
    "\n",
    "# Usage\n",
    "avg_loss, perplexity, accuracy = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Test Perplexity: {perplexity:.2f}\")\n",
    "print(f\"Token-level Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5e9409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T05:24:59.655872Z",
     "iopub.status.busy": "2025-12-27T05:24:59.655304Z",
     "iopub.status.idle": "2025-12-27T05:24:59.658838Z",
     "shell.execute_reply": "2025-12-27T05:24:59.658192Z"
    },
    "papermill": {
     "duration": 12.049295,
     "end_time": "2025-12-27T05:24:59.660490",
     "exception": false,
     "start_time": "2025-12-27T05:24:47.611195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # Recreate the model architecture\n",
    "# model = LSTMTST(vocab_size).to(device)\n",
    "\n",
    "# # Load the saved weights\n",
    "# model.load_state_dict(torch.load(\"/kaggle/input/pretrained-lstm/pytorch/default/1/best_model.pt\", map_location=device))\n",
    "\n",
    "# # Set model to evaluation mode\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc3dd35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T05:25:23.705862Z",
     "iopub.status.busy": "2025-12-27T05:25:23.705267Z",
     "iopub.status.idle": "2025-12-27T05:25:24.065403Z",
     "shell.execute_reply": "2025-12-27T05:25:24.064560Z"
    },
    "papermill": {
     "duration": 12.489824,
     "end_time": "2025-12-27T05:25:24.067167",
     "exception": false,
     "start_time": "2025-12-27T05:25:11.577343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃទី២ ខែកុម្ភៈ ឆ្នាំ២០១៦ នៅចំណុចកណ្តាលនៃការប្រើប្រាស់កម្លាំង និងប្រជាជន និងប្រជាជន និងប្រជាជន និងប្រជា\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"គ្រោះថ្នាក់ចរាចរណ៍ទូទាំងប្រទេសថ្ងៃ\"\n",
    "tokens = [stoi[ch] for ch in seed_text if ch in stoi]\n",
    "\n",
    "# generate next 100 characters\n",
    "generated = tokens.copy()\n",
    "for _ in range(100):\n",
    "    input_seq = torch.tensor([generated[-seq_len:]]).to(device)  # last seq_len tokens\n",
    "    logits, _ = model(input_seq)\n",
    "    next_token = logits[:, -1, :].argmax(dim=-1).item()\n",
    "    generated.append(next_token)\n",
    "\n",
    "# convert back to characters\n",
    "generated_text = \"\".join([itos[t] for t in generated])\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9104670,
     "sourceId": 14267558,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3200.362056,
   "end_time": "2025-12-27T05:25:38.870645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-27T04:32:18.508589",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
